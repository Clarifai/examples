---
language: multilingual
---


## Twitter xlm-roberta-base for sentiment analysis

This is a multilingual XLM-roBERTa-base model trained on ~198M tweets and finetuned for sentiment analysis. The sentiment fine-tuning was done on 8 languages (Ar, En, Fr, De, Hi, It, Sp, Pt) but it can be used for more languages (see paper for details).

- Paper: [XLM-T: A Multilingual Language Model Toolkit for Twitter](https://arxiv.org/abs/2104.12250).
- Official Github Repository: [XLM-T official repository](https://github.com/cardiffnlp/xlm-t).
- Sentiment Classes: Negative, Neutral, Positive
