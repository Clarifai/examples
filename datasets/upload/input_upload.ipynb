{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9dafe5",
   "metadata": {},
   "source": [
    "<td>\n",
    "   <a target=\"_blank\" href=\"https://www.clarifai.com/\" ><img src=\"https://upload.wikimedia.org/wikipedia/commons/b/bc/Clarifai_Logo_FC_Web.png\" width=256/></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4889a76",
   "metadata": {},
   "source": [
    "<td>\n",
    "<a href=\"https://colab.research.google.com/github/Clarifai/examples/blob/main/datasets/upload/input_upload.ipynb\" target=\"_blank\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Colab\"></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aac5f5c",
   "metadata": {},
   "source": [
    "# Input Upload\n",
    "\n",
    "Inputs are basically data in Clarifai App. Clarifai App supports unstructured data that includes Image, Text, Video and Audio types. These inputs then can be used for Annotation, Model Training , Model Prediction and for Workflow Predictions. \n",
    "\n",
    "This notebook consists of\n",
    "- Upload data with metadata\n",
    "- Upload data with geoinfo\n",
    "- Upload image bounding box annotation\n",
    "- Upload image polygon points annotation\n",
    "- Upload text with annotation\n",
    "- Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c4a80",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb036d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U clarifai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e8009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Replace your PAT\n",
    "os.environ['CLARIFAI_PAT'] = \"YOUR_PAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e275697f",
   "metadata": {},
   "source": [
    "*Note: Guide to get your [PAT](https://docs.clarifai.com/clarifai-basics/authentication/personal-access-tokens)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e21904c",
   "metadata": {},
   "source": [
    "## Upload Data with Geoinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154c7db0",
   "metadata": {},
   "source": [
    "Provide a geo point to an input. The geo point consists of a longitude and a latitude in GPS coordinate system. There can be at most one single geo point associated with each input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0357944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clarifai.client.input import Inputs\n",
    "#replace your \"user_id\", \"app_id\", \"dataset_id\".\n",
    "input_object = Inputs(user_id=\"user_id\", app_id=\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb963edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#geo_info=[longitude, latitude]\n",
    "url = \"https://samples.clarifai.com/Ferrari.jpg\"\n",
    "geo_points = [102,73]\n",
    "input_object.upload_from_url(input_id=\"geo_info\",image_url=url,geo_info=geo_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c00ca",
   "metadata": {},
   "source": [
    "## Upload Data with Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf2d195",
   "metadata": {},
   "source": [
    "In addition to adding an input with concepts, you can also add an input with custom metadata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a399566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.struct_pb2 import Struct\n",
    "metadata = Struct()\n",
    "metadata.update({\"filename\": \"XiJinping.jpg\", \"split\": \"train\"})\n",
    "url = \"https://samples.clarifai.com/XiJinping.jpg\"\n",
    "input_object.upload_from_url(input_id=\"metadata\",image_url=url,metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d795fcf",
   "metadata": {},
   "source": [
    "## Upload Image Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5146489d",
   "metadata": {},
   "source": [
    "### Bounding Box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b54464",
   "metadata": {},
   "source": [
    "Below is an example of how to label a new rectangular bounding box for a region.\n",
    "- The bounding box normalized to the data dimension to be within [0-1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0070e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input upload\n",
    "url = \"https://samples.clarifai.com/BarackObama.jpg\"\n",
    "input_object.upload_from_url(input_id=\"bbox\",image_url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation upload\n",
    "bbox_points = [.1,.1,.8,.9]\n",
    "annotation = input_object.get_bbox_proto(input_id=\"bbox\", label=\"face\", bbox=bbox_points)\n",
    "input_object.upload_annotations([annotation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8799be",
   "metadata": {},
   "source": [
    "### Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9c65e",
   "metadata": {},
   "source": [
    "An example of how to provide annotations within any polygon-shaped region of an image.\n",
    "\n",
    "These are the list of points that connect together to form a polygon:\n",
    "- row—The row location of the point. This has a [0.0-1.0] range with 0.0 being top row and 1.0 being the bottom row;\n",
    "- col—The column location of the point. This has a [0.0-1.0] range with 0.0 being left col and 1.0 being the right col;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input upload\n",
    "url = \"https://samples.clarifai.com/airplane.jpeg\"\n",
    "input_object.upload_from_url(input_id=\"mask\",image_url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotation upload\n",
    "#polygons=[[[x,y],...,[x,y]],...]\n",
    "polygon_pts = [[.15,.24],[.4,.78],[.77,.62],[.65,.15]]\n",
    "annotation = input_object.get_mask_proto(input_id=\"mask\", label=\"airplane\", polygons=polygon_pts)\n",
    "input_object.upload_annotations([annotation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8744a8",
   "metadata": {},
   "source": [
    "## Upload Text Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://samples.clarifai.com/featured-models/Llama2_Conversational-agent.txt\"\n",
    "concepts = [\"mobile\",\"camera\"]\n",
    "input_object.upload_from_url(input_id=\"text14\",text_url=url, labels=concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15adfe3",
   "metadata": {},
   "source": [
    "## Download Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_object.download_inputs(list(input_object.list_inputs()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a80955",
   "metadata": {},
   "source": [
    "## Patch Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b56e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.struct_pb2 import Struct\n",
    "metadata = Struct()\n",
    "metadata.update({'split': 'test'})\n",
    "new_input = input_object._get_proto(input_id='input_id', metadata= metadata)\n",
    "input_object.patch_inputs([new_input],action='merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069fbbb0",
   "metadata": {},
   "source": [
    "## Patch Image Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb5e03",
   "metadata": {},
   "source": [
    "### Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_points = [.4,.4,.5,.5]\n",
    "annotation = input_object.get_bbox_proto(input_id=\"input_id\", label=\"label\", bbox=bbox_points, annot_id=\"annotation_id\")\n",
    "input_object.patch_annotations([annotation],action='merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709ef26",
   "metadata": {},
   "source": [
    "### Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygon_pts = [[.1,.1],[.1,.9],[.9,.9],[.9,.1]]\n",
    "annotation = input_object.get_mask_proto(input_id=\"input_id\", label=\"label\", polygons=polygon_pts, annot_id=\"annotation_id\")\n",
    "input_object.patch_annotations([annotation],action='merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87657240",
   "metadata": {},
   "source": [
    "## Patch Image Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7533649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_object.patch_concepts(concept_ids=[\"concept_id1\",\"concept_id2\"],labels=[\"label1\",\"label2\"],values=[1.,1.],action='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a61244",
   "metadata": {},
   "source": [
    "## Delete Input Annotations\n",
    "\n",
    "`annotation_ids` are optional but if the are provided, the number and order in `annotation_ids` and `input_ids` should match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24810c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_object.delete_annotations(input_ids=[\"input_id1\", \"input_id1\", \"input_id2\"],annotation_ids=[\"annot_id11\", \"annot_id12\", \"annot_id21\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994654b1",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d18d8f",
   "metadata": {},
   "source": [
    "- This example shows removing unicode from text and uploading them to Clarifai Platform.\n",
    "- You can add your own custom functionalities with ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e762d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unicode_and_upload(input_id, text):\n",
    "    string_encode = text.encode(\"ascii\", \"ignore\")\n",
    "    string_decode = string_encode.decode()\n",
    "    input_object.upload_text(input_id=input_id,raw_text=string_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63dbfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_unicode_and_upload(input_id='demo',text = \"This is a test \\u200c example. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a9b76",
   "metadata": {},
   "source": [
    "## Clarifai Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d01c6",
   "metadata": {},
   "source": [
    "**Website**: [https://www.clarifai.com](https://www.clarifai.com/)\n",
    "\n",
    "**Demo**: [https://clarifai.com/demo](https://clarifai.com/demo)\n",
    "\n",
    "**Sign up for a free Account**: [https://clarifai.com/signup](https://clarifai.com/signup)\n",
    "\n",
    "**Developer Guide**: [https://docs.clarifai.com](https://docs.clarifai.com/)\n",
    "\n",
    "**Clarifai Community**: [https://clarifai.com/explore](https://clarifai.com/explore)\n",
    "\n",
    "**Python SDK Docs**: [https://docs.clarifai.com/python-sdk/api-reference](https://docs.clarifai.com/python-sdk/api-reference)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
