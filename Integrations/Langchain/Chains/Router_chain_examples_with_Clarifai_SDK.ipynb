{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td>\n",
    "   <a target=\"_blank\" href=\"https://www.clarifai.com/\" ><img src=\"https://upload.wikimedia.org/wikipedia/commons/b/bc/Clarifai_Logo_FC_Web.png\" width=256/></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td>\n",
    "<a href=\"https://colab.research.google.com/github/Clarifai/examples/blob/main/Integrations/Langchain/Chains/Router_chain_examples_with_Clarifai_SDK.ipynb\" target=\"_blank\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Colab\"></a>\n",
    "</td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gA84A4FscMO7"
   },
   "source": [
    "# **Router chain with Clarifai SDK prompt templates**\n",
    "\n",
    "This notebook will walk you through a demo on when and how to use Router chain from langchain in an effective way and leverage it to use for variety of tasks in your AI Apps.\n",
    "\n",
    "For the purpose of demo we going to create various prompt templates based on the Clarifai-python SDK use cases and test the router chain implementation based on these templates for variety of scenarios.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Chains**\n",
    "While using a language model (LLM) on its own is good for simple tasks, tackling more complex applications often requires connecting multiple LLMs either with each other or with different parts of the system.\n",
    "\n",
    "LangChain provides various chains frameworks for connecting these components. \n",
    "Explore about various [Chains](https://python.langchain.com/docs/modules/chains/) in langchain and also it provides different ways to encompass [memory](https://python.langchain.com/docs/modules/memory/) into the chain which will add additional capabilities to your AI apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWASBaJiE9IT"
   },
   "source": [
    "### Setup\n",
    "#### Install the latest langchain package and Clarifai package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P7t6mLrUKxAK"
   },
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install clarifai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzQ479NDFVQ_"
   },
   "source": [
    "You can use several language models from [Clarifai](https://clarifai.com/explore/models?filterData=%5B%7B%22field%22%3A%22use_cases%22%2C%22value%22%3A%5B%22llm%22%5D%7D%5D&page=1&perPage=24) platform. Sign up and get your [PAT](https://clarifai.com/settings/security) to access it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_hTIOFCOeSp"
   },
   "source": [
    "For our example we are using codellama-34b-instruct model.\n",
    "\n",
    "##[Codellama](https://huggingface.co/codellama)\n",
    "\n",
    "* Code Llama is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 34 billion parameters.\n",
    "* This model is designed for general code synthesis and understanding.\n",
    "* This use case where we are trying to modify our code and run it might be one of the specialized use cases for using codellama-34b-instruct model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "gqw7lLCDM39-"
   },
   "outputs": [],
   "source": [
    "MODEL_URL=\"https://clarifai.com/meta/Llama-2/models/codellama-34b-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSw6ahcuOeb8"
   },
   "source": [
    "Initialize your PAT key as environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "HiiIqPfqOUUE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CLARIFAI_PAT\"]=\"YOUR_CLARIFAI_PAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the global debug flag will cause all LangChain components with callback support (chains, models, agents, tools, retrievers) to print the inputs they receive and outputs they generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YIr2rYyF9Fm"
   },
   "source": [
    "### **Clarifai LLM**\n",
    "You can access different models from clarifai platform within langchain framework. By signing up to clarifai and getting a clarifai's PAT token you can access LLM models, embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "lmGKIGbqOLL-"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import Clarifai\n",
    "llm=Clarifai(model_url=MODEL_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "MGDabp-8ON6m"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlPvLMw7GQ54"
   },
   "source": [
    "### **Prompt Templates**\n",
    "\n",
    "For the demo of router chains we are creating different types of prompt templates which gives us an executable code of our own [Clarifai-Python](https://github.com/Clarifai/clarifai-python) SDK. These are used to perform simple mundane tasks with clarifai platform like creating/deleting apps, datasets, ingestion of imputs and prediction of concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "KbiKsivfOyjD"
   },
   "outputs": [],
   "source": [
    "ingest_input_image_template= PromptTemplate(input_variables=[\"input\"], template=(\"\"\"\n",
    "You are an programmer with deep understanding of python code, If user wants to ingest image data/inputs into their clarifai app,\\\n",
    "then you need to carefully go through the user query and retrieve certain parameters needed for the below code to execute.\\\n",
    "retrieve userid, appid and image_url from the user Input : {input} and fill the parameters and return below code output which is ready to be executed.\\\n",
    "Check further if the user wants to ingest list of inputs, if so use for loop inside code to upload.\n",
    "```python\n",
    "from clarifai.client.user import User\n",
    "clarifai_app = User(User_id).app(App_id)\n",
    "input_obj = app.inputs()\n",
    "res=input_obj.upload_from_url(input_id=\"id-1\", image_url=url)\n",
    "print(\"Inputs added successfully\")\n",
    "````\n",
    "Don't give any alternate suggestions, return only the code in above format with minor changes.!\n",
    "\"\"\"),\n",
    ")\n",
    "\n",
    "ingest_input_text_template = PromptTemplate.from_template( \"\"\"\n",
    "You are an programmer with deep understanding of python code, If user wants to ingest text data/inputs into their clarifai app,\\\n",
    "then you need to carefully go through the user query and retrieve certain parameters needed for the below code to execute.\\\n",
    "retrieve userid, appid and text_url from the user Input : {input} and fill the parameters and return below code output which is ready to be executed.\\\n",
    "Check further if the user wants to ingest list of inputs, if so use for loop inside code to upload.\n",
    "```python\n",
    "from clarifai.client.user import User\n",
    "clarifai_app = User(User_id).app(App_id)\n",
    "input_obj = app.inputs()\n",
    "res=input_obj.upload_from_url(input_id=\"i\", text_url=url)\n",
    "print(\"Inputs added successfully\")\n",
    "````\n",
    "Don't give any alternate suggestions, return only the code in above format with minor changes.!\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "create_app_template= PromptTemplate.from_template(\"\"\"\n",
    "As a Python programmer with a deep understanding of code, your task is to help users to create their Clarifai app using the Clarifai Python SDK.\n",
    "Carefully go through the user's query and retrieve the necessary parameters from user's prompt for the below provided code snippet and fill the parameters\\\n",
    "and return below code which is ready to be executed.\n",
    "For creating apps make sure the user's : {input} consists of 'user_id', 'app_id', 'base_workflow'(optional).\n",
    "```python\n",
    "from clarifai.client.user import User\n",
    "client = User(user_id=\"user_id\")\n",
    "app = client.create_app(app_id=\"app_id\", base_workflow=\"Universal\")\n",
    "print(\"App created successfully\")\n",
    "```\n",
    "Don't give any alternate suggestions, return only the code in above format with minor changes.!\n",
    " \"\"\")\n",
    "\n",
    "delete_app_template=PromptTemplate.from_template(\"\"\"\n",
    "As a Python programmer with a deep understanding of code, your task is to help users to delete Clarifai app using the Clarifai Python SDK.\n",
    "Carefully go through the user's query and retrieve the necessary parameters from user's prompt for the below provided code snippet and fill the parameters\\\n",
    "and return below python code which is ready to be executed.\n",
    "For deleting dataset make sure the user's : {input} consists of 'user_id', 'app_id'.\n",
    "```python\n",
    "from clarifai.client.user import User\n",
    "user = User(\"user_id\").delete_app(\"app_id\")\n",
    "print(\"App deleted successfully\")\n",
    "```\n",
    "Don't give any alternate suggestions, return only the code in above format with minor changes.!\n",
    "\"\"\")\n",
    "\n",
    "create_dataset_template= PromptTemplate.from_template(\"\"\"\n",
    "As a Python programmer with a deep understanding of code, your task is to help users to create dataset inside Clarifai app using the Clarifai Python SDK.\n",
    "Carefully go through the user's query and retrieve the necessary parameters from user's prompt for the below provided code snippet and fill the parameters\\\n",
    "and return below code which is ready to be executed.\n",
    "For creating dataset make sure the user's : {input} consists of 'user_id', 'app_id', 'dataset_id'.\n",
    "```python\n",
    "from clarifai.client.app import App\n",
    "app = App(app_id=\"app_id\", user_id=\"user_id\")\n",
    "dataset = app.create_dataset(dataset_id=\"dataset_id\")\n",
    "print(\"dataset created successfully)\n",
    "```\n",
    "Don't give any alternate suggestions, return only the code in above format with minor changes.!\n",
    "\"\"\")\n",
    "\n",
    "delete_dataset_template= PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "As a Python programmer with a deep understanding of code, your task is to help users to delete dataset inside Clarifai app using the Clarifai Python SDK.\n",
    "Carefully go through the user's query and retrieve the necessary parameters from user's prompt for the below provided code snippet and fill the parameters\\\n",
    "and return below code which is ready to be executed.\n",
    "For deleting dataset make sure the user's : {input} consists of 'user_id', 'app_id', 'dataset_id'.\n",
    "Don't give any alternate suggestions, return only the code in above format with minor changes.!\n",
    "```python\n",
    "from clarifai.client.app import App\n",
    "app = App(app_id=\"app_id\", user_id=\"user_id\")\n",
    "app.delete_dataset(dataset_id=\"dataset_id\")\n",
    "print(\"dataset deleted successfully)\n",
    "```\n",
    "Don't give any alternate suggestions, return only the code in above format with minor changes.!\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "predict_model_template= PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "As a Python programmer with a deep understanding of code, your task is to help users to predict concepts from image using the Clarifai Python SDK.\n",
    "Carefully go through the user's query and retrieve the necessary parameters from user's prompt for the below provided code snippet and fill the parameters\\\n",
    "and return below code which is ready to be executed.\n",
    "For predicting concepts using clarifai SDK make sure the user's : {input} consists of 'model_url'(optional) and 'image_url'.\n",
    "If no model_url is given use Example model_url: https://clarifai.com/clarifai/main/models/general-image-recognition.\n",
    "```python\n",
    "from clarifai.client.model import Model\n",
    "model = Model(\"model_url\")\n",
    "model_prediction = model.predict_by_url(url='image_url', input_type='image')\n",
    "for concept in model_prediction.outputs[0].data.concepts:\n",
    "  print('name :', concept.name, ',', 'score:', concept.value)\n",
    "```\n",
    "Don't give any alternate suggestions, return only the code in above format with minor changes.!\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uHl--VLCHE03"
   },
   "source": [
    "### Chains from prompt templates\n",
    "\n",
    "So now that we have prompt templates for various scenarios, the next step is to create a proper chains based on these templates. Make sure to give appropriate description for each prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "O8NlbugunRhM"
   },
   "outputs": [],
   "source": [
    "#Prompt infos store the description and template details of the corresponding stage. We can add more descriptions to obtain crispy results.\n",
    "\n",
    "prompt_infos=[\n",
    "    {\n",
    "        \"name\" : \"Ingest image inputs\",\n",
    "        \"description\" : \"When Image inputs needs to be ingested into clarifai app\",\n",
    "        \"prompt_template\" : ingest_input_image_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"Ingest text inputs\",\n",
    "        \"description\" : \"To ingest text inputs into clarifai app\",\n",
    "        \"prompt_template\" : ingest_input_text_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"create clarifai app\",\n",
    "        \"description\" : \"To create clarifai app for the user\",\n",
    "        \"prompt_template\" : create_app_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"delete clarifai app\",\n",
    "        \"description\" : \"To delete clarifai app for the user\",\n",
    "        \"prompt_template\" : delete_app_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"create dataset\",\n",
    "        \"description\" : \"To create dataset inside clarifai app for the user\",\n",
    "        \"prompt_template\" : create_dataset_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"delete dataset\",\n",
    "        \"description\" : \"To delete dataset inside clarifai app for the user\",\n",
    "        \"prompt_template\" : delete_dataset_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"predict concepts\",\n",
    "        \"description\" : \"To predict concepts for the given image using clarifai model URL\",\n",
    "        \"prompt_template\" : predict_model_template,\n",
    "    }\n",
    "\n",
    "]\n",
    "\n",
    "#storing the prompt template name and chain info in a dictionary.\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# In case if user's query is not based on the above templates we need to make sure to have a base default chain to address such conditions.\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOYwO6VsIhB6"
   },
   "source": [
    "### Creating LLMrouterChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYRZv5__kVLP"
   },
   "source": [
    "After we have our chains created for each prompt templates, we'll create a router chain class which helps routing  queries to appropriate prompt templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WYfCcYO5u5-2",
    "outputId": "7536a6c8-1c81-4d7e-9450-c6faeb0e6c42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest image inputs: When Image inputs needs to be ingested into clarifai app\n",
      "Ingest text inputs: To ingest text inputs into clarifai app\n",
      "create clarifai app: To create clarifai app for the user\n",
      "delete clarifai app: To delete clarifai app for the user\n",
      "create dataset: To create dataset inside clarifai app for the user\n",
      "delete dataset: To delete dataset inside clarifai app for the user\n",
      "predict concepts: To predict concepts for the given image using clarifai model URL\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEibxrjAkpJM"
   },
   "source": [
    "Custom function to prepare our LLM response for post processing. We will pass the output into the function to achieve our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "fABJv0qfCqxr"
   },
   "outputs": [],
   "source": [
    "def runquery(llmresponse):\n",
    "  _, after = llmresponse.split(\"```python\")\n",
    "  code=after.split(\"```\")[0]\n",
    "  exec(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Sucj4FkkzRc"
   },
   "source": [
    "###Observations\n",
    "Let's dive into predictions part where we'll test our Router pipeline with several scenarios and check if it is routing to appropriate prompt templates to generate response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "yG0BSf4L55-R",
    "outputId": "9dc43d06-595c-4f7e-b431-7d1610c657e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create clarifai app: {'input': 'my_app_2 mogith-p-n'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "### Solution\n",
      "\n",
      "```python\n",
      "from clarifai.client.user import User\n",
      "client = User(user_id=\"mogith-p-n\")\n",
      "app = client.create_app(app_id=\"my_app_2\", base_workflow=\"Universal\")\n",
      "print(\"App created successfully\")\n",
      "```\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2023-12-19 14:17:08 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> clarifai.client.user:                                                      <a href=\"file:///usr/local/lib/python3.10/dist-packages/clarifai/client/user.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">user.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.10/dist-packages/clarifai/client/user.py#122\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         App created                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         code: SUCCESS                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         description: <span style=\"color: #008000; text-decoration-color: #008000\">\"Ok\"</span>                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         req_id: <span style=\"color: #008000; text-decoration-color: #008000\">\"8502d132dfe77c09f984a41694bdd03d\"</span>                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2023-12-19 14:17:08\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m clarifai.client.user:                                                      \u001b]8;id=237050;file:///usr/local/lib/python3.10/dist-packages/clarifai/client/user.py\u001b\\\u001b[2muser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=652191;file:///usr/local/lib/python3.10/dist-packages/clarifai/client/user.py#122\u001b\\\u001b[2m122\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         App created                                                                \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         code: SUCCESS                                                              \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         description: \u001b[32m\"Ok\"\u001b[0m                                                          \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         req_id: \u001b[32m\"8502d132dfe77c09f984a41694bdd03d\"\u001b[0m                                 \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                    \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">2023-12-19 14:17:08 </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> clarifai.client.user:                                                      <a href=\"file:///usr/local/lib/python3.10/dist-packages/clarifai/client/user.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">user.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///usr/local/lib/python3.10/dist-packages/clarifai/client/user.py#122\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         App created                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         code: SUCCESS                                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         description: <span style=\"color: #008000; text-decoration-color: #008000\">\"Ok\"</span>                                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         req_id: <span style=\"color: #008000; text-decoration-color: #008000\">\"8502d132dfe77c09f984a41694bdd03d\"</span>                                 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m2023-12-19 14:17:08\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m clarifai.client.user:                                                      \u001b]8;id=493885;file:///usr/local/lib/python3.10/dist-packages/clarifai/client/user.py\u001b\\\u001b[2muser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=569987;file:///usr/local/lib/python3.10/dist-packages/clarifai/client/user.py#122\u001b\\\u001b[2m122\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         App created                                                                \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         code: SUCCESS                                                              \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         description: \u001b[32m\"Ok\"\u001b[0m                                                          \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         req_id: \u001b[32m\"8502d132dfe77c09f984a41694bdd03d\"\u001b[0m                                 \u001b[2m           \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                    \u001b[2m           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:clarifai.client.user:\n",
      "App created\n",
      "code: SUCCESS\n",
      "description: \"Ok\"\n",
      "req_id: \"8502d132dfe77c09f984a41694bdd03d\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App created successfully\n"
     ]
    }
   ],
   "source": [
    "response=chain.run(\"I want to create clarifai app 'my_app_2' in my account 'mogith-p-n'?\")\n",
    "print(response)\n",
    "runquery(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_9AOxdyO0dF"
   },
   "source": [
    "We got our clarifai App created successfully with just single line of query.\n",
    "You can observe how our model just simplifies the task by producing a super executable code which in turn we can pass it to our AI pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRRWMKcR2qAp",
    "outputId": "63f7671c-c245-43cc-b657-44784b936c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete clarifai app: {'input': \"I want to delete clarifai app 'my_app' in my account 'mogith-p-n'\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "App deleted successfully\n"
     ]
    }
   ],
   "source": [
    "response=chain.run(\"I want to delete clarifai app 'my_app' in my account 'mogith-p-n'?\")\n",
    "runquery(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oC3BgCELQBSm"
   },
   "source": [
    "Note that the chain actually showcases which Prompt template it has been used for this particular scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qi_sRBlhO_yS"
   },
   "source": [
    "Now try to ingest some inputs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNyRyl8bRFW_",
    "outputId": "649c155f-2379-4ea8-ef69-f91745ca7a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest image inputs: {'input': \"I want to ingest these images https://images.pexels.com/photos/139257/pexels-photo-139257.jpeg, https://images.pexels.com/photos/139247/pexels-photo-139247.jpeg into app 'my_app' in my clarifai account mogith-p-n.\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Image 1 added successfully\n",
      "Image 2 added successfully\n"
     ]
    }
   ],
   "source": [
    "query=\"I want to ingest these images https://images.pexels.com/photos/139257/pexels-photo-139257.jpeg, https://images.pexels.com/photos/139247/pexels-photo-139247.jpeg into app 'my_app' in my clarifai account mogith-p-n.\"\n",
    "resp=chain.run(query)\n",
    "runquery(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GE6k29KPC6R"
   },
   "source": [
    "Let's try prediction on image with a simple query,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOM63qAQ-6Tq",
    "outputId": "b703c0b7-5dc8-4652-b65e-2e8c5e04d54e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict concepts: {'input': \"Detect what's in this image https://images.pexels.com/photos/139257/pexels-photo-139257.jpeg\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "name : no person , score: 0.9926819205284119\n",
      "name : summer , score: 0.984977126121521\n",
      "name : beach , score: 0.9845458269119263\n",
      "name : nature , score: 0.9790793657302856\n",
      "name : sand , score: 0.976331353187561\n",
      "name : water , score: 0.9747101664543152\n",
      "name : sky , score: 0.9711887836456299\n",
      "name : travel , score: 0.9610219597816467\n",
      "name : tropical , score: 0.9548453688621521\n",
      "name : sun , score: 0.9491840600967407\n",
      "name : sea , score: 0.946053683757782\n",
      "name : sunset , score: 0.9431171417236328\n",
      "name : outdoors , score: 0.916150689125061\n",
      "name : composure , score: 0.8943774104118347\n",
      "name : dune , score: 0.881453812122345\n",
      "name : exotic , score: 0.8704201579093933\n",
      "name : relaxation , score: 0.8697872757911682\n",
      "name : romance , score: 0.86239093542099\n",
      "name : seashore , score: 0.8560242652893066\n",
      "name : recreation , score: 0.8548668026924133\n"
     ]
    }
   ],
   "source": [
    "query=\"Detect what's in this image https://images.pexels.com/photos/139257/pexels-photo-139257.jpeg\"\n",
    "resp=chain.run(query)\n",
    "runquery(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tp3s5JLQcXA"
   },
   "source": [
    "How cool is to just detect the concepts in the given image with just simple prompt. by the way the model detect actually uses one of clarifai's benchmark [image detection](https://clarifai.com/clarifai/main/models/general-image-recognition) model to predict concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarifai Resources\n",
    "\n",
    "**Website**: [https://www.clarifai.com](https://www.clarifai.com/)\n",
    "\n",
    "**Demo**: [https://clarifai.com/demo](https://clarifai.com/demo)\n",
    "\n",
    "**Sign up for a free Account**: [https://clarifai.com/signup](https://clarifai.com/signup)\n",
    "\n",
    "**Developer Guide**: [https://docs.clarifai.com](https://docs.clarifai.com/)\n",
    "\n",
    "**Clarifai Community**: [https://clarifai.com/explore](https://clarifai.com/explore)\n",
    "\n",
    "**Python SDK Docs**: [https://docs.clarifai.com/python-sdk/api-reference](https://docs.clarifai.com/python-sdk/api-reference)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
