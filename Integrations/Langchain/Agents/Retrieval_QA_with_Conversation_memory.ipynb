{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTlx_Nhr4nrV"
   },
   "source": [
    "# Retrieval QA using Clarifai Vectorstore with Conversation memory.\n",
    "\n",
    "The notebook walks you through the high level concept and idea to build a chatbot Doc Q/A in using clarifai as vectorstore and langchain's conversationbuffermemory. This enables the user to have a context of recent chat history in buffer as well as helping the user to query about document stored in the DB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqjkG_y794nk"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "I7ERa_Fn7s32",
    "outputId": "70326ae7-0252-4bd9-9d59-0f8118fc49e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.350-py3-none-any.whl (809 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.2 (from langchain)\n",
      "  Downloading langchain_community-0.0.3-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain)\n",
      "  Downloading langchain_core-0.1.1-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
      "  Downloading langsmith-0.0.71-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m463.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
      "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.350 langchain-community-0.0.3 langchain-core-0.1.1 langsmith-0.0.71 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "Collecting clarifai\n",
      "  Downloading clarifai-9.11.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.7/182.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting clarifai-grpc==9.11.0 (from clarifai)\n",
      "  Downloading clarifai_grpc-9.11.0-py3-none-any.whl (222 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.2/222.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.10/dist-packages (from clarifai) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from clarifai) (1.23.5)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from clarifai) (4.66.1)\n",
      "Collecting opencv-python==4.7.0.68 (from clarifai)\n",
      "  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tritonclient==2.34.0 (from clarifai)\n",
      "  Downloading tritonclient-2.34.0-py3-none-manylinux1_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich>=13.4.2 in /usr/local/lib/python3.10/dist-packages (from clarifai) (13.7.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from clarifai) (6.0.1)\n",
      "Collecting schema==0.7.5 (from clarifai)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Collecting Pillow>=9.5.0 (from clarifai)\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio>=1.44.0 in /usr/local/lib/python3.10/dist-packages (from clarifai-grpc==9.11.0->clarifai) (1.60.0)\n",
      "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from clarifai-grpc==9.11.0->clarifai) (3.20.3)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.53.0 in /usr/local/lib/python3.10/dist-packages (from clarifai-grpc==9.11.0->clarifai) (1.62.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.10/dist-packages (from clarifai-grpc==9.11.0->clarifai) (2.31.0)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from schema==0.7.5->clarifai) (21.6.0)\n",
      "Collecting python-rapidjson>=0.9.1 (from tritonclient==2.34.0->clarifai)\n",
      "  Downloading python_rapidjson-1.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->clarifai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.5->clarifai) (2023.3.post1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.4.2->clarifai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.4.2->clarifai) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.4.2->clarifai) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3.5->clarifai) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->clarifai-grpc==9.11.0->clarifai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->clarifai-grpc==9.11.0->clarifai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->clarifai-grpc==9.11.0->clarifai) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.25.1->clarifai-grpc==9.11.0->clarifai) (2023.11.17)\n",
      "Installing collected packages: schema, python-rapidjson, Pillow, opencv-python, tritonclient, clarifai-grpc, clarifai\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.4.0\n",
      "    Uninstalling Pillow-9.4.0:\n",
      "      Successfully uninstalled Pillow-9.4.0\n",
      "  Attempting uninstall: opencv-python\n",
      "    Found existing installation: opencv-python 4.8.0.76\n",
      "    Uninstalling opencv-python-4.8.0.76:\n",
      "      Successfully uninstalled opencv-python-4.8.0.76\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-10.1.0 clarifai-9.11.0 clarifai-grpc-9.11.0 opencv-python-4.7.0.68 python-rapidjson-1.14 schema-0.7.5 tritonclient-2.34.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "PIL"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#install necessary packages\n",
    "!pip install langchain\n",
    "!pip install clarifai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oz5eDa4CKcce"
   },
   "source": [
    "Create your own Clarifai account to access several language models from [Clarifai](https://clarifai.com/explore/models?filterData=%5B%7B%22field%22%3A%22use_cases%22%2C%22value%22%3A%5B%22llm%22%5D%7D%5D&page=1&perPage=24) platform. Sign up and get your [PAT](https://clarifai.com/settings/security) to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaVMNyGtKo8y"
   },
   "outputs": [],
   "source": [
    "#Note we also have an option to pass the PAT key directly while calling the classes, so user can either intialize it as env variable or arguments.\n",
    "import os\n",
    "os.environ[\"CLARIFAI_PAT\"]=\"YOUR_CLARIFAI_PAT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlFdWlqEK4bS"
   },
   "source": [
    "### Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pXQm3c7EynoT"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import Clarifai as Clarifaivectorstore\n",
    "from langchain.llms import Clarifai as Clarifaillm\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG2QjuRNKCam"
   },
   "source": [
    "### Preparing Docs for ingestion into our vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ohZlmy5J-8b"
   },
   "outputs": [],
   "source": [
    "loader = TextLoader(\"/content/rule_book.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xlpn6TFhSUwN"
   },
   "source": [
    "Initialize the Clarifai Vector DB using your PAT, app id and user id. You can give any number of docs for the Top K document retrieval value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8iN5xY9v8ak4"
   },
   "outputs": [],
   "source": [
    "clarifai_vector_db = Clarifai.from_documents(\n",
    "    user_id=\"user_name\",\n",
    "    app_id= \"app_name\",\n",
    "    documents=docs,\n",
    "    number_of_docs=3,\n",
    "    pat=\"YOUR_CLARIFAI_PAT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcLQMKRTSlOL"
   },
   "source": [
    "Initialize a llm model through clarifaiLLM class. We are creating a langchain's conversationalbuffer memory and a retrieal QA chain.\n",
    "So basically the retrieval QA chain acts as an agent here and fetches the document when the query is related to contents from document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-zrrOqdf5FyZ"
   },
   "outputs": [],
   "source": [
    "MODEL_URL = \"https://clarifai.com/openai/chat-completion/models/GPT-4\"\n",
    "\n",
    "llm=Clarifaillm(model_url=MODEL_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pPmZtUM8TTgV"
   },
   "source": [
    "The **K we are using here sets the bufferwindow for chat memory**, whereas the no_of_documents we set in the previous stage in clarifaivectorstore is to retrieve top_k docs based on the query from vectorDB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7C0pZTQ6TR13"
   },
   "outputs": [],
   "source": [
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=3,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "retrieve_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=clarifai_vector_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "empD-oz6Tjii"
   },
   "source": [
    "Testing whether our Retrieval QA chain is working perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "GGVn-38s5MDV",
    "outputId": "cab11a19-7f00-4953-8657-9fac3cdf2479"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Automobile classes have been segregated with respect to engines as follows:\\n\\n1. F1 Grand Prix cars with 3L aspirated engines built from 1970 to 1972. This class is further divided into cars equipped with a Ford-Cosworth DFV Engine and those equipped with other engines.\\n\\n2. F1 Grand Prix cars with 3L aspirated engines built from 1973 to 1976. This class is also divided into cars equipped with a Ford-Cosworth DFV Engine and those equipped with other engines.\\n\\n3. F1 Grand Prix cars with 3L aspirated engines built from 1977 to 1980. This class is divided into cars designed not to exploit the ground effect, cars designed to exploit the ground effect equipped with a Ford-Cosworth DFV engine, and cars designed to exploit the ground effect equipped with other engines.\\n\\n4. Cars equipped with a Ford-Cosworth DFV engine.\\n\\n5. F1 Grand Prix cars 3L aspirated built from 1981 to 1985.\\n\\n6. Cars equipped with other engines.\\n\\nAdditionally, there is a Special Invitation Class for any Formula One cars or any other cars considered of Special Historical interest to the Organization or Promoters of any of the races, or particular benefit to the Organization.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_chain.run(\"How automobile classes has been segregated with respect to engines?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7gFHVp8Trw1"
   },
   "source": [
    "## Clarifai Vectorstore as Tool\n",
    "Now the task is to make this retrieval QA chain into something like a chatbot which also provides a conversational experience with previous messages contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YVkqVOn9KH7"
   },
   "outputs": [],
   "source": [
    "#initialize an Tool with our clarifaivectorstore as retrieval agent.\n",
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Guide document',\n",
    "        func=retrieve_chain.run,\n",
    "        description=(\n",
    "            'use this tool when answering about automobile related queries especially related to F1-70s rulebook chnages to get '\n",
    "            'more information about the topic'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "The core idea of agents is to use a language model to choose a sequence of actions to take. In agents, a language model is used as a reasoning engine to determine which actions to take and in which order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Agent\n",
    "\n",
    "- This agent is designed to be used in conversational settings. \n",
    "- The prompt is designed to make the agent helpful and conversational. \n",
    "- It uses the ReAct framework to decide which tool to use, and uses memory to remember the previous conversation interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put all pieces together, we are building a chatbot with a conversational_memory as well a retrieval agent which fetches relevant docs to chat with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GDOYpNO-Neg"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "chat_agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    early_stopping_method='generate',\n",
    "    handle_parsing_errors=True,\n",
    "    memory=conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "datF3e4BUgjk"
   },
   "source": [
    "## Observations\n",
    "Now we execute the some queries to understand the functionality and usage of this agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "5JE7Xcx--SI2",
    "outputId": "2f4e78bd-cf2a-4634-e7c3-7c77d1ec8b28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Guide document\",\n",
      "    \"action_input\": \"Automobile classes and engine segregation\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe automobile classes and engine segregation mentioned in the text can be summarized as follows:\n",
      "\n",
      "1. F1 Grand Prix cars with a 3L aspirated engine built from 1977 to 1980. These are further divided into:\n",
      "   - Cars designed not to exploit the ground effect.\n",
      "   - Cars designed to exploit the ground effect, equipped with a Ford-Cosworth DFV engine.\n",
      "   - Cars designed to exploit the ground effect, equipped with other engines.\n",
      "\n",
      "2. Cars equipped with a Ford-Cosworth DFV engine. \n",
      "\n",
      "3. F1 Grand Prix cars with a 3L aspirated engine built from 1981 to 1985. \n",
      "\n",
      "4. Cars equipped with other engines. \n",
      "\n",
      "5. Class Special Invitation: This class is for any Formula One cars or any other cars considered by the Organization to be of Special Historical interest to the Organization or Promoters of any of the races, or of particular benefit to the Organization.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The segregation of automobile classes with respect to engines, as per the information obtained, can be detailed as follows: \\n\\n1. F1 Grand Prix cars with a 3L aspirated engine built from 1977 to 1980 are divided into: \\n   - Cars not designed to exploit the ground effect. \\n   - Cars designed to exploit the ground effect, equipped with a Ford-Cosworth DFV engine. \\n   - Cars designed to exploit the ground effect, equipped with other engines. \\n\\n2. There's a class for cars equipped with a Ford-Cosworth DFV engine. \\n\\n3. Another class is for F1 Grand Prix cars with a 3L aspirated engine built from 1981 to 1985. \\n\\n4. There's also a class for cars equipped with other engines. \\n\\n5. The 'Class Special Invitation' is for any Formula One cars or any other cars considered to be of Special Historical interest to the Organization or Promoters of any of the races, or of particular benefit to the Organization.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The segregation of automobile classes with respect to engines, as per the information obtained, can be detailed as follows: \\n\\n1. F1 Grand Prix cars with a 3L aspirated engine built from 1977 to 1980 are divided into: \\n   - Cars not designed to exploit the ground effect. \\n   - Cars designed to exploit the ground effect, equipped with a Ford-Cosworth DFV engine. \\n   - Cars designed to exploit the ground effect, equipped with other engines. \\n\\n2. There's a class for cars equipped with a Ford-Cosworth DFV engine. \\n\\n3. Another class is for F1 Grand Prix cars with a 3L aspirated engine built from 1981 to 1985. \\n\\n4. There's also a class for cars equipped with other engines. \\n\\n5. The 'Class Special Invitation' is for any Formula One cars or any other cars considered to be of Special Historical interest to the Organization or Promoters of any of the races, or of particular benefit to the Organization.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.run(\"How automobile classes has been segregated with respect to engines?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNwaE6rfUtk-"
   },
   "source": [
    "So when we re-instructed the bot to perform similar task without any context it can able to digest it and produce the results as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "_uG-U7qYeZW0",
    "outputId": "3d3fe481-67cf-4b6f-f712-37ffd9558a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Automobile classes, especially in the context of Formula 1 racing, are typically segregated based on engine specifications and design characteristics. Here's a brief summary:\n",
      "\n",
      "1. Class for F1 Grand Prix cars (1977-1980) not designed to exploit the ground effect.\n",
      "2. Class for F1 Grand Prix cars (1977-1980) designed to exploit the ground effect, equipped with a Ford-Cosworth DFV engine.\n",
      "3. Class for F1 Grand Prix cars (1977-1980) designed to exploit the ground effect, equipped with other engines.\n",
      "4. Class for cars equipped with a Ford-Cosworth DFV engine.\n",
      "5. Class for F1 Grand Prix cars (1981-1985).\n",
      "6. Class for cars equipped with other engines.\n",
      "7. Special Invitation Class: reserved for any Formula One cars or any other cars considered to be of Special Historical interest or of particular benefit to the Organization.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Automobile classes, especially in the context of Formula 1 racing, are typically segregated based on engine specifications and design characteristics. Here's a brief summary:\\n\\n1. Class for F1 Grand Prix cars (1977-1980) not designed to exploit the ground effect.\\n2. Class for F1 Grand Prix cars (1977-1980) designed to exploit the ground effect, equipped with a Ford-Cosworth DFV engine.\\n3. Class for F1 Grand Prix cars (1977-1980) designed to exploit the ground effect, equipped with other engines.\\n4. Class for cars equipped with a Ford-Cosworth DFV engine.\\n5. Class for F1 Grand Prix cars (1981-1985).\\n6. Class for cars equipped with other engines.\\n7. Special Invitation Class: reserved for any Formula One cars or any other cars considered to be of Special Historical interest or of particular benefit to the Organization.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.run(\"Just summarize the classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "TGOt9GBECMa5",
    "outputId": "d7f0a321-4350-4881-efa1-8fd8b7e187dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Guide document\",\n",
      "    \"action_input\": \"summarize the new rules from the document\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe document outlines rules related to protests, appeals, and safety and discipline in a race event. Protests must be written and submitted within 30 minutes after the provisional classification, and they require a fee. The exact fee amount will be stated in an Event Bulletin. However, appeals cannot be made against decisions concerning several items, including a Drive Through Penalty, a Timed Stop & Go Penalty, any Time Penalty, decisions taken by the Stewards in relation to Article 23.4.2, penalties under Article 27.7 or Article 30.2, and decisions made by timekeepers and other Judges of Fact. \n",
      "\n",
      "In terms of general safety and discipline, the Clerk of the Course can request additional formation laps if conditions require. If additional laps are necessary, the start is considered to have been given at the end of the first formation lap. The document also suggests there are specific cases in which a variation in the start procedure is allowed, but these cases aren't specified in the provided context.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The document you referenced outlines rules related to protests, appeals, and safety and discipline in race events. Protests must be written and submitted within 30 minutes following the provisional classification, and they require a fee, the amount of which will be stated in an Event Bulletin. However, appeals cannot be made against decisions concerning several items, including a Drive Through Penalty, a Timed Stop & Go Penalty, any Time Penalty, decisions taken by the Stewards in relation to certain articles, penalties under specific articles, and decisions made by timekeepers and other Judges of Fact. \n",
      "\n",
      "In terms of general safety and discipline, the Clerk of the Course can request additional formation laps if conditions require. If additional laps are necessary, the start is considered to have been given at the end of the first formation lap. The document also suggests there are specific cases in which a variation in the start procedure is allowed, but these cases aren't specified in the obtained information.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The document you referenced outlines rules related to protests, appeals, and safety and discipline in race events. Protests must be written and submitted within 30 minutes following the provisional classification, and they require a fee, the amount of which will be stated in an Event Bulletin. However, appeals cannot be made against decisions concerning several items, including a Drive Through Penalty, a Timed Stop & Go Penalty, any Time Penalty, decisions taken by the Stewards in relation to certain articles, penalties under specific articles, and decisions made by timekeepers and other Judges of Fact. \\n\\nIn terms of general safety and discipline, the Clerk of the Course can request additional formation laps if conditions require. If additional laps are necessary, the start is considered to have been given at the end of the first formation lap. The document also suggests there are specific cases in which a variation in the start procedure is allowed, but these cases aren't specified in the obtained information.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.run(\"summarize the new rules from the document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLTIWmc9U6ri"
   },
   "source": [
    "#### Okay, What if when we asks some random question to our agent ?."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "hoPo83F9DCHp",
    "outputId": "fa9fcaa7-b214-4b21-e44b-3adf38588392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The Big Bang Theory is a cosmological model that describes the universe's observable development from the earliest known periods through its subsequent large-scale evolution. The model describes how the universe expanded from an extremely high-density and high-temperature state, and offers a comprehensive explanation for a broad range of observed phenomena, including the abundance of light elements, the cosmic microwave background (CMB) radiation, and the large scale structure of the cosmos. The Big Bang Theory does not explain why the universe was created or what occurred before the event itself, as these questions fall into the realm of philosophy or theology.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The Big Bang Theory is a cosmological model that describes the universe's observable development from the earliest known periods through its subsequent large-scale evolution. The model describes how the universe expanded from an extremely high-density and high-temperature state, and offers a comprehensive explanation for a broad range of observed phenomena, including the abundance of light elements, the cosmic microwave background (CMB) radiation, and the large scale structure of the cosmos. The Big Bang Theory does not explain why the universe was created or what occurred before the event itself, as these questions fall into the realm of philosophy or theology.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.run(\"what is story of big bang theory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgOBtSApVHUB"
   },
   "source": [
    "So in above context our agent just did a action observation by itself and found that it doesn't need the agent to answer for the query and went ahead straight to generate response for the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "1hkpHv_kDGkd",
    "outputId": "91166da9-3266-4123-e3b2-c896eef423bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The Big Bang Theory is an American television sitcom that aired from 2007 to 2019. It was created by Chuck Lorre and Bill Prady. The show is primarily centered around five characters living in Pasadena, California: Leonard Hofstadter and Sheldon Cooper, both physicists at Caltech, who share an apartment; Penny, a waitress and aspiring actress who later becomes a pharmaceutical representative and who lives across the hall; and Leonard and Sheldon's similarly geeky and socially awkward friends and co-workers, aerospace engineer Howard Wolowitz and astrophysicist Raj Koothrappali. The geekiness and intellect of the four men are contrasted for comic effect with Penny's social skills and common sense. Over time, supporting characters were promoted to starring roles, including neuroscientist Amy Farrah Fowler, microbiologist Bernadette Rostenkowski, physicist Leslie Winkle and comic book store owner Stuart Bloom.\"\n",
      "}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The Big Bang Theory is an American television sitcom that aired from 2007 to 2019. It was created by Chuck Lorre and Bill Prady. The show is primarily centered around five characters living in Pasadena, California: Leonard Hofstadter and Sheldon Cooper, both physicists at Caltech, who share an apartment; Penny, a waitress and aspiring actress who later becomes a pharmaceutical representative and who lives across the hall; and Leonard and Sheldon's similarly geeky and socially awkward friends and co-workers, aerospace engineer Howard Wolowitz and astrophysicist Raj Koothrappali. The geekiness and intellect of the four men are contrasted for comic effect with Penny's social skills and common sense. Over time, supporting characters were promoted to starring roles, including neuroscientist Amy Farrah Fowler, microbiologist Bernadette Rostenkowski, physicist Leslie Winkle and comic book store owner Stuart Bloom.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_agent.run(\"I meant the series story\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-3IZzNJVlQv"
   },
   "source": [
    "So even when I re-instructed the prompt with a different query but in the same context, it was able to perceive it since we have our chat memory in conversation and produce results based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aApxsNL8BdFF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
