{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4266a1ca",
   "metadata": {},
   "source": [
    "![image](https://github.com/user-attachments/assets/b22c9807-f5e7-49eb-b00d-598e400781af)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cc1e7c",
   "metadata": {},
   "source": [
    "# Clarifai - Google ADK \n",
    "This notebook shows a basic example of how to use clarifai CO models with Google ADK library "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d827e",
   "metadata": {},
   "source": [
    "### Weather Agent Tutorial ðŸŒ¦ï¸\n",
    "\n",
    "This notebook demonstrates how to build and interact with a weather information agent using Google ADK, OpenAI/Clarifai models, and custom tool integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d96be8",
   "metadata": {},
   "source": [
    "#### Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93033718",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-adk litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f209947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# @title Import necessary libraries\n",
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909650fe",
   "metadata": {},
   "source": [
    "### Setup your PAT key\n",
    "Set your Clarifai PAT as environment variable.\n",
    "Below we will be using Clarifai PAT as alias for OPENAI API KEY, since we are using Clarifai models in OpenAI compatible endpoints format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ad495",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CLARIFAI_PAT=\"YOUR_CLARIFAI_PAT\"  # Set your Clarifai PAT here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa33e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarifai_pat = os.getenv('CLARIFAI_PAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ca491",
   "metadata": {},
   "source": [
    "### Clarifai LLM model\n",
    "Google ADK uses LiteLLM underhood to call the LLM models. It also allows to pass the openai compatible endpoints by using the base url and model name.\n",
    "\n",
    "##### Using Clarifai Models\n",
    "\n",
    "Clarifai models can be accessed using LiteLLM in the below model URL format:\n",
    "Starts with prefix `openai` - \n",
    "\n",
    "`openai/{user_id}/{app_id}/models/{model_id}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf04b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarifai_model = LiteLlm(model=\"openai/openai/chat-completion/models/gpt-4o\",\n",
    "                      base_url=\"https://api.clarifai.com/v2/ext/openai/v1\",\n",
    "                      api_key=clarifai_pat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3e548",
   "metadata": {},
   "source": [
    "### Available Models\n",
    "\n",
    "You can explore available models on the [Clarifai Community](https://clarifai.com/explore) platform. Some popular models include:\n",
    "\n",
    "- GPT-4: `openai/chat-completion/models/gpt-4o`\n",
    "- Gemini 2.5 Flash: `gcp/generate/models/gemini-2_5-flash`\n",
    "- Llama 2: `meta/Llama-2/models/llama2-70b-chat`\n",
    "- Mixtral: `mistralai/Mixtral-8x7B/models/mixtral-8x7b-instruct`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53306054",
   "metadata": {},
   "source": [
    "#### Tool definition\n",
    "In this below snippet, we are setting up the `get_weather` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e0fcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25Â°C.'}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
     ]
    }
   ],
   "source": [
    "# @title Define the get_weather Tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the weather information.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'report' key with weather details.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\") # Log tool execution\n",
    "    city_normalized = city.lower().replace(\" \", \"\") # Basic normalization\n",
    "\n",
    "    # Mock weather data\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25Â°C.\"},\n",
    "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15Â°C.\"},\n",
    "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18Â°C.\"},\n",
    "    }\n",
    "\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
    "\n",
    "# Example tool usage (optional test)\n",
    "print(get_weather(\"New York\"))\n",
    "print(get_weather(\"Paris\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a2826",
   "metadata": {},
   "source": [
    "#### Agent Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0144e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define Agent Interaction Function\n",
    "\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "async def call_agent_async(query: str, runner, user_id, session_id):\n",
    "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "  print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "  # Prepare the user's message in ADK format\n",
    "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "\n",
    "  # Key Concept: run_async executes the agent logic and yields Events.\n",
    "  # We iterate through events to find the final answer.\n",
    "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "      # You can uncomment the line below to see *all* events during execution\n",
    "      # print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "      if event.is_final_response():\n",
    "          if event.content and event.content.parts:\n",
    "             # Assuming text response in the first part\n",
    "             final_response_text = event.content.parts[0].text\n",
    "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "          # Add more checks here if needed (e.g., specific error codes)\n",
    "          break # Stop processing events once the final response is found\n",
    "\n",
    "  print(f\"<<< Agent Response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2b3aef",
   "metadata": {},
   "source": [
    "#### Calling Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "353d9d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created: App='weather_tutorial_app_gpt', User='user_1_gpt', Session='session_001_gpt'\n",
      "Runner created for agent 'weather_agent_gpt'.\n",
      "\n",
      "--- Testing GPT Agent ---\n",
      "\n",
      ">>> User Query: What's the weather in Tokyo?\n",
      "--- Tool: get_weather called for city: Tokyo ---\n",
      "<<< Agent Response: In Tokyo, the weather is currently experiencing light rain with a temperature of 18Â°C.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# @title 1. Import LiteLlm\n",
    "from google.adk.models.lite_llm import LiteLlm\n",
    "# @title Define and Test GPT Agent\n",
    "\n",
    "# Make sure 'get_weather' function from Step 1 is defined in your environment.\n",
    "# Make sure 'call_agent_async' is defined from earlier.\n",
    "\n",
    "# --- Agent using GPT-4o ---\n",
    "weather_agent_gpt = None # Initialize to None\n",
    "runner_gpt = None      # Initialize runner to None\n",
    "\n",
    "try:\n",
    "    weather_agent_gpt = Agent(\n",
    "        name=\"weather_agent_gpt\",\n",
    "        # Key change: Wrap the LiteLLM model identifier\n",
    "        model=clarifai_model,\n",
    "        description=\"Provides weather information (using GPT-4o).\",\n",
    "        instruction=\"You are a helpful weather assistant powered by GPT-4o. \"\n",
    "                    \"Use the 'get_weather' tool for city weather requests. \"\n",
    "                    \"Clearly present successful reports or polite error messages based on the tool's output status.\",\n",
    "        tools=[get_weather], # Re-use the same tool\n",
    "    )\n",
    "\n",
    "    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "    session_service_gpt = InMemorySessionService() # Create a dedicated service\n",
    "\n",
    "    # Define constants for identifying the interaction context\n",
    "    APP_NAME_GPT = \"weather_tutorial_app_gpt\" # Unique app name for this test\n",
    "    USER_ID_GPT = \"user_1_gpt\"\n",
    "    SESSION_ID_GPT = \"session_001_gpt\" # Using a fixed ID for simplicity\n",
    "\n",
    "    # Create the specific session where the conversation will happen\n",
    "    session_gpt = await session_service_gpt.create_session(\n",
    "        app_name=APP_NAME_GPT,\n",
    "        user_id=USER_ID_GPT,\n",
    "        session_id=SESSION_ID_GPT\n",
    "    )\n",
    "    print(f\"Session created: App='{APP_NAME_GPT}', User='{USER_ID_GPT}', Session='{SESSION_ID_GPT}'\")\n",
    "\n",
    "    # Create a runner specific to this agent and its session service\n",
    "    runner_gpt = Runner(\n",
    "        agent=weather_agent_gpt,\n",
    "        app_name=APP_NAME_GPT,       # Use the specific app name\n",
    "        session_service=session_service_gpt # Use the specific session service\n",
    "        )\n",
    "    print(f\"Runner created for agent '{runner_gpt.agent.name}'.\")\n",
    "\n",
    "    # --- Test the GPT Agent ---\n",
    "    print(\"\\n--- Testing GPT Agent ---\")\n",
    "    # Ensure call_agent_async uses the correct runner, user_id, session_id\n",
    "    await call_agent_async(query = \"What's the weather in Tokyo?\",\n",
    "                           runner=runner_gpt,\n",
    "                           user_id=USER_ID_GPT,\n",
    "                           session_id=SESSION_ID_GPT)\n",
    "    # --- OR ---\n",
    "\n",
    "    # Uncomment the following lines if running as a standard Python script (.py file):\n",
    "    # import asyncio\n",
    "    # if __name__ == \"__main__\":\n",
    "    #     try:\n",
    "    #         asyncio.run(call_agent_async(query = \"What's the weather in Tokyo?\",\n",
    "    #                      runner=runner_gpt,\n",
    "    #                       user_id=USER_ID_GPT,\n",
    "    #                       session_id=SESSION_ID_GPT)\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"An error occurred: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Could not create or run GPT agent. Check API Key and model name. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adkclarifai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
