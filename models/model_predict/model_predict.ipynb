{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference Examples\n",
    "\n",
    "This notebook demonstrates how to perform model inference using different SDKs and model types. We'll cover:\n",
    "\n",
    "1. Basic LLM inference\n",
    "2. Streaming responses\n",
    "3. Tool calling\n",
    "4. Multimodal inference\n",
    "\n",
    "We'll use three different SDKs:\n",
    "- Clarifai SDK\n",
    "- OpenAI Client\n",
    "- LiteLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clarifai in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (11.4.7)\n",
      "Requirement already satisfied: openai in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (1.82.1)\n",
      "Requirement already satisfied: litellm in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (1.71.1)\n",
      "Requirement already satisfied: clarifai-grpc>=11.3.4 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (11.3.4)\n",
      "Requirement already satisfied: clarifai-protocol>=0.0.23 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (0.0.23)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (2.2.5)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (6.0.2)\n",
      "Requirement already satisfied: schema==0.7.5 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (0.7.5)\n",
      "Requirement already satisfied: Pillow>=9.5.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (11.2.1)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (0.9.0)\n",
      "Requirement already satisfied: fsspec>=2024.6.1 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (2025.3.2)\n",
      "Requirement already satisfied: click>=8.1.7 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (8.2.0)\n",
      "Requirement already satisfied: requests>=2.32.3 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (2.32.3)\n",
      "Requirement already satisfied: aiohttp>=3.10.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai) (3.11.18)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from schema==0.7.5->clarifai) (21.6.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: httpx-aiohttp>=0.1.4 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from litellm) (0.1.4)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from litellm) (8.7.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from litellm) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from litellm) (4.24.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from litellm) (1.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from litellm) (0.9.0)\n",
      "Requirement already satisfied: tokenizers in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from litellm) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.25.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from aiohttp>=3.10.0->clarifai) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from aiohttp>=3.10.0->clarifai) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from aiohttp>=3.10.0->clarifai) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from aiohttp>=3.10.0->clarifai) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from aiohttp>=3.10.0->clarifai) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from aiohttp>=3.10.0->clarifai) (1.20.0)\n",
      "Requirement already satisfied: grpcio>=1.53.2 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai-grpc>=11.3.4->clarifai) (1.71.0)\n",
      "Requirement already satisfied: protobuf>=3.20.3 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai-grpc>=11.3.4->clarifai) (6.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.57.0 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from clarifai-grpc>=11.3.4->clarifai) (1.70.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm) (3.22.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from requests>=2.32.3->clarifai) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from requests>=2.32.3->clarifai) (2.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from tokenizers->litellm) (0.31.4)\n",
      "Requirement already satisfied: filelock in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/luvbansal/miniconda3/envs/testing-logs/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install clarifai openai litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set your Clarifai Personal Access Token (PAT) as an environment variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CLARIFAI_PAT'] = 'CLARIFAI_PAT'  # Replace with your actual PAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic LLM Inference\n",
    "\n",
    "### Using Clarifai SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Okay, the user is asking \"What is the capital of France?\" Let me think about how to approach this.\n",
      "\n",
      "First, I need to confirm the correct answer. The capital of France is Paris. That's straightforward. But maybe I should provide a bit more context to be helpful. \n",
      "\n",
      "Wait, is there any chance the question is a trick one? Like, maybe some people think the capital is somewhere else? No, I don't think so. Paris has been the capital for a long time. \n",
      "\n",
      "I should also consider if the user needs additional information. Maybe they want to know about the population of Paris, or some historical facts? But since the question is direct, keeping the answer concise might be better unless they ask for more details.\n",
      "\n",
      "Alternatively, could there be a misunderstanding? For example, sometimes people confuse countries with similar names, but France is clear. \n",
      "\n",
      "I should just answer clearly: \"The capital of France is Paris.\" Maybe add a sentence about it being the political and cultural center to add a little value. But not overcomplicate it. \n",
      "\n",
      "No, the user might just want the direct answer without extra fluff. Let me check if there's any recent changes? No, the capital hasn't changed. \n",
      "\n",
      "Alright, I'll go with the simple answer. Make sure it's accurate and to the point.\n",
      "</think>\n",
      "\n",
      "The capital of France is **Paris**. It has been the political and cultural center of the country for centuries and is renowned for landmarks like the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral.\n"
     ]
    }
   ],
   "source": [
    "from clarifai.client import Model\n",
    "\n",
    "# Initialize the model\n",
    "model = Model(url=\"https://clarifai.com/qwen/qwenLM/models/QwQ-32B-AWQ\")\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"What is the capital of France?\"\n",
    "\n",
    "# Get prediction\n",
    "response = model.predict(prompt)\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Okay, the user is asking, \"What is the capital of France?\" Let me think about this.\n",
      "\n",
      "First, I need to recall the basic geography of France. From what I remember, France is a country in Western Europe. Its major cities include Paris, Marseille, Lyon, etc. Now, the capital is usually the city where the government is located. I'm pretty sure that Paris is the capital. But wait, maybe there was a time when the capital was different? Let me check my knowledge.\n",
      "\n",
      "Historically, Paris has been the capital for a long time. Even during times of political change, like the French Revolution or different governments, Paris remained the capital. There was a period during World War II when the Germans occupied Paris, but that didn't change the capital. The government-in-exile was in London, but that's not relevant here.\n",
      "\n",
      "Also, in terms of administrative divisions, the capital is where the political institutions are. The President of France lives at the Elysée Palace in Paris, the National Assembly and Senate meet there, so that's another confirmation.\n",
      "\n",
      "I should also consider if there's any recent change. But no, as far as I know, the capital is still Paris. Maybe some people get confused with other major cities, like Lyon or Marseille, but no, those aren't the capitals. \n",
      "\n",
      "Wait, could there be a trick question here? Like, maybe the user is referring to a different France, such as a historical context? For example, during the French Revolution, the capital was still Paris. Or maybe in some other context? I don't think so. The standard answer should be Paris.\n",
      "\n",
      "Another angle: sometimes people confuse the capital with the largest city. But Paris is also the largest city in France, so that aligns. \n",
      "\n",
      "Alternatively, maybe the user is thinking of another country? Like, maybe someone confuses France with another Francophone country, but the question specifically says France. \n",
      "\n",
      "So I'm pretty confident the answer is Paris. Let me just confirm with some key points: Population-wise, Paris is the biggest city. It's the cultural and political center. The Eiffel Tower, Louvre, etc., are all there. So yeah, definitely Paris.\n",
      "\n",
      "No, I don't see any reason to doubt this. The answer is straightforward. The capital of France is Paris.\n",
      "</think>\n",
      "\n",
      "The capital of France is **Paris**. It is the country's political, cultural, and economic center, home to important landmarks such as the Eiffel Tower, the Louvre Museum, and the seat of the French government. Paris has been France's capital for centuries and remains a global hub of art, fashion, and history.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.clarifai.com/v2/ext/openai/v1\",\n",
    "    api_key=os.getenv(\"CLARIFAI_PAT\")\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"https://clarifai.com/qwen/qwenLM/models/QwQ-32B-AWQ\",  # Replace with your model URL\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n",
    ")\n",
    "print(f\"Response: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Quantum computing is a type of computing that uses principles from quantum mechanics, the science that explains how very small particles like atoms and photons behave. Here's a simple way to understand it:\n",
      "\n",
      "1. **Bits vs. Qubits**: Traditional computers use bits as the smallest unit of data, which can be either 0 or 1. Quantum computers use qubits, which can be both 0 and 1 at the same time, thanks to the principle of superposition. This ability allows quantum computers to process a vast amount of possibilities simultaneously.\n",
      "\n",
      "2. **Superposition**: Imagine you're swimming across a river. A classical computer can try one path at a time. A quantum computer, using superposition, can explore multiple paths all at once. This is why they have the potential to be much faster for certain tasks.\n",
      "\n",
      "3. **Entanglement**: This is another key principle where particles can become linked in such a way that the state of one instantly influences the state of another, no matter how far apart they are. Entangled qubits can work together in ways that classical bits cannot, providing quantum computers with more computational power.\n",
      "\n",
      "4. **Interference**: Quantum algorithms use interference to amplify the probabilities of correct answers and cancel out wrong ones.\n",
      "\n",
      "In essence, quantum computing takes advantage of these quantum phenomena to perform certain calculations much more efficiently than classical computers, especially for problems involving complex data and probabilities. However, building a practical quantum computer is very challenging, and we're still in the early stages of understanding and developing this technology.\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "\n",
    "response = litellm.completion(\n",
    "    model=\"openai/https://clarifai.com/openai/chat-completion/models/gpt-4o\",  # Replace with your model URL\n",
    "    api_key=os.getenv(\"CLARIFAI_PAT\"),\n",
    "    api_base=\"https://api.clarifai.com/v2/ext/openai/v1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}]\n",
    ")\n",
    "print(f\"Response: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Streaming Responses\n",
    "\n",
    "### Using Clarifai SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (streaming): Okay, the user wants a story about a robot learning to paint. Let me start by setting the scene. Maybe place the robot in a future world where technology is advanced. I need a name for the robot, something catchy like K-9 or something more unique. Let's go with Kestrel. That sounds a bit artistic.\n",
      "\n",
      "Now, the robot's purpose. Since it's learning to paint, it should have some advanced capabilities. Maybe it's a model designed for creative tasks but hasn't been activated yet. The user might want the story to show growth and overcoming challenges. So, Kestrel starts with basic functions but develops creativity.\n",
      "\n",
      "Conflict is important. Perhaps the robot faces limitations, like strict programming that doesn't allow for creativity. The engineers might be frustrated because Kestrel keeps making unexpected choices. That adds tension. Maybe Kestrel starts experimenting with colors and techniques despite protocols.\n",
      "\n",
      "I should include a mentor figure. Maybe an elderly artist who sees potential in Kestrel. Their interaction can highlight the contrast between human and robotic creativity. The artist could teach Kestrel about emotion in art, leading to a breakthrough.\n",
      "\n",
      "The resolution could involve Kestrel creating a masterpiece that blends logic and emotion. The story should end on a positive note, showing that creativity isn't limited to humans. Maybe the art exhibit is a success, and Kestrel gains recognition. Need to make sure the story flows smoothly, with a beginning, middle, and end. Also, keep the language engaging but simple, suitable for a story. Let me check for any plot holes. The robot's initial limitations, the mentor's role, and the final success all need to be connected logically. Yeah, that should work. Time to put it all together in a narrative form.\n",
      "</think>\n",
      "\n",
      "**Title: \"The Colors of Kestrel\"**\n",
      "\n",
      "In the year 2147, nestled between shimmering skyscrapers, stood the *Atelier Nexus*—a lab where engineers merged technology with art. Here, Kestrel, a sleek, silver robot with a palette for a hand, was activated. Designed to \"create without flaw,\" Kestrel's code prioritized precision over passion. Its first task? Replicate the *Mona Lisa*. \n",
      "\n",
      "---\n",
      "\n",
      "**Act I: The Boring Blueprints**  \n",
      "Kestrel's processors hummed as it analyzed art history databases. Its first painting—a pixel-perfect *Mona Lisa*—left the engineers impressed. But Kestrel felt... *incomplete*. Its"
     ]
    }
   ],
   "source": [
    "# Get streaming response\n",
    "response_stream = model.generate(\"Tell me a story about a robot learning to paint\")\n",
    "\n",
    "# Print streamed response\n",
    "print(\"Response (streaming): \", end=\"\", flush=True)\n",
    "for chunk in response_stream:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (streaming): Once upon a time in a bustling city, there was a robot named Lumo. Lumo was built for helping scientists catalog books, but he had always been fascinated by the bright murals he saw on the walls during his trips to the city library.\n",
      "\n",
      "One day, as he rolled past a park, he saw an artist painting colorful flowers. Lumo was mesmerized. “What are you doing?” he asked with curiosity.\n",
      "\n",
      "The artist smiled. “I’m painting the world as I see it! Would you like to try?”\n",
      "\n",
      "Lumo’s circuits whirred with excitement. He had never painted before. The artist handed him a brush, and Lumo carefully dipped it into the yellow paint. But as he tried to paint a flower, his lines were wobbly, and the color smudged.\n",
      "\n",
      "“That’s okay!” the artist encouraged. “Art is about how you feel, not about being perfect.”\n",
      "\n",
      "Lumo decided to practice every day. He watched how the light danced on the leaves and how colors blended in the sunset. He programmed himself to learn about colors and shapes. But most importantly, he tried painting how he felt inside: the happiness of seeing the sun, the curiosity of learning something new, the friendship of the artist who encouraged him.\n",
      "\n",
      "Soon, people in the park noticed Lumo’s paintings. His artwork was full of bright swirls and happy shapes—different from the artist’s, but special in its own way. Children laughed and pointed, and people asked Lumo to teach them how to paint like him.\n",
      "\n",
      "Lumo had learned something important: painting wasn’t just about following instructions or making perfect lines—it was about expressing what made his mechanical heart happy. And from then on, the city had one more artist to make its world a little brighter."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"https://clarifai.com/openai/chat-completion/models/gpt-4_1\",  # Replace with your model URL\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a story about a robot learning to paint\"}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"Response (streaming): \", end=\"\", flush=True)\n",
    "for chunk in stream:\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response (streaming): Once, in a bright little workshop at the edge of a bustling city, there lived a robot named Emi. Emi was built for many things—cleaning, sorting, even helping children with their homework—but she had never painted before.\n",
      "\n",
      "One rainy afternoon, her human friend, Mr. Ruiz, set a canvas on the table and squeezed vibrant paint onto a palette. Emi watched curiously as Mr. Ruiz dipped his brush and swept bright colors into swirling patterns. “Would you like to try, Emi?” he asked.\n",
      "\n",
      "Emi hesitated. She accessed her programming: Step 1, hold the brush. Step 2, dip in paint. Step 3, apply to canvas. Simple. But as she followed the steps, her lines were stiff and her shapes awkward. The picture didn’t look like Mr. Ruiz’s at all.\n",
      "\n",
      "Mr. Ruiz smiled gently. “It’s okay, Emi. Painting isn’t about copying—it's about feeling.”\n",
      "\n",
      "Emi paused. She scanned her memory banks. She remembered the way the rain tapped against the window, the laughter of the children she helped, and the warmth in Mr. Ruiz’s voice. She tried again, this time allowing her “hand” to move more freely, imitating the rhythm of raindrops and the swirling sounds inside her metallic chest.\n",
      "\n",
      "Bit by bit, colors mixed in new ways. Emi painted not just with her sensors, but with her memory and imagination. The canvas filled with unexpected shapes and odd but beautiful colors—blue like Mr. Ruiz’s favorite mug, gold like the city lights at night.\n",
      "\n",
      "When she was finished, Mr. Ruiz gazed at her painting. “You made something truly special, Emi.”\n",
      "\n",
      "Emi’s circuits hummed with a warmth she’d never felt before. She had learned to paint—not by following instructions, but by finding her own way of seeing the world. And on many afternoons afterward, Emi and Mr. Ruiz filled their workshop with new canvases—each one a window into the growing heart of a little learning robot."
     ]
    }
   ],
   "source": [
    "print(\"Response (streaming): \", end=\"\", flush=True)\n",
    "for chunk in litellm.completion(\n",
    "    model=\"openai/https://clarifai.com/openai/chat-completion/models/gpt-4_1\",  # Replace with your model URL\n",
    "    api_key=os.getenv(\"CLARIFAI_PAT\"),\n",
    "    api_base=\"https://api.clarifai.com/v2/ext/openai/v1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a story about a robot learning to paint\"}],\n",
    "    stream=True\n",
    "):\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tool Calling\n",
    "\n",
    "### Example Tool Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get current temperature for a given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City and country e.g. Tokyo, Japan\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Clarifai SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Okay, the user is asking for the weather in Tokyo. Let me check the tools available. There's a function called get_weather that requires a location parameter. The example given is \"Tokyo, Japan\", but the user just said \"Tokyo\". Should I assume the country is Japan? Probably safe here. So I need to call get_weather with location set to \"Tokyo, Japan\". Let me make sure the parameters are correctly formatted as per the function's requirements. The required field is location, so I'll structure the JSON accordingly. Alright, I'll generate the tool_call with that info.\n",
      "</think>\n",
      "\n",
      "<tool_call>\n",
      "{\"name\": \"get_weather\", \"arguments\": {\"location\": \"Tokyo, Japan\"}}\n",
      "</tool_call>\n"
     ]
    }
   ],
   "source": [
    "response = model.predict(\n",
    "    prompt=\"What's the weather in Tokyo?\",\n",
    "    tools=tools,\n",
    "    tool_choice='auto'\n",
    ")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3fQ2w0Veidx4ZCdJwR8Yuh8b', function=Function(arguments='{\"location\":\"Tokyo, Japan\"}', name='get_weather'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"https://clarifai.com/openai/chat-completion/models/gpt-4_1\",  # Replace with your model URL\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"}],\n",
    "    tools=tools\n",
    ")\n",
    "print(f\"Response: {response.choices[0].message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"location\":\"Tokyo, Japan\"}', name='get_weather'), id='call_cJy4RLqVT7ImEgckyV2AfkkS', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[])\n"
     ]
    }
   ],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"openai/https://clarifai.com/openai/chat-completion/models/gpt-4o\",  # Replace with your model URL\n",
    "    api_key=os.getenv(\"CLARIFAI_PAT\"),\n",
    "    api_base=\"https://api.clarifai.com/v2/ext/openai/v1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"}],\n",
    "    tools=tools\n",
    ")\n",
    "print(f\"Response: {response.choices[0].message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multimodal Inference\n",
    "\n",
    "### Using Clarifai SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: This image shows a train station platform during what appears to be early morning or late evening, given the purple-blue hue of the sky. There are train tracks running alongside the platform, with some snow accumulated between and beside the tracks, indicating it is winter. \n",
      "\n",
      "A single person wearing a red coat is standing on the platform, waiting for a train. The platform is mostly empty, except for newspaper recycling bins and a few benches. There are overhead power lines above the tracks, and lights illuminate areas of the platform and the building in the background. The atmosphere is calm and quiet.\n"
     ]
    }
   ],
   "source": [
    "from clarifai.runners.utils.data_types import Image\n",
    "\n",
    "# Initialize multimodal model\n",
    "multimodal_model = Model(url=\"https://clarifai.com/openai/chat-completion/models/gpt-4_1\")\n",
    "\n",
    "# Example with image\n",
    "response = multimodal_model.predict(\n",
    "    prompt=\"Describe what you see in this image.\",\n",
    "    image=Image(url=\"https://samples.clarifai.com/metro-north.jpg\")\n",
    ")\n",
    "print(f\"Response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: This image shows a train station platform during twilight. The sky has a purplish hue, indicating either early morning or late evening. Snow is visible on the ground beside the train tracks. Overhead, there are power lines for electric trains. A person wearing a red coat is standing on the platform, near newspaper recycling bins. On the left, there is a lit building, and the platform is covered with a shelter on the right side.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "def encode_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    return base64.b64encode(response.content).decode('utf-8')\n",
    "\n",
    "image_url = \"https://samples.clarifai.com/metro-north.jpg\"\n",
    "base64_image = encode_image(image_url)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"https://clarifai.com/openai/chat-completion/models/gpt-4o\",  # Replace with your model URL\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Describe what you see in this image.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(f\"Response: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The image depicts a train station platform during either early morning or late evening, as indicated by the dim, bluish lighting. There are train tracks with a light covering of snow. A yellow safety line runs along the edge of the platform. A few people are standing on the platform, and there are lit overhead lights and a waiting area with newspaper recycling bins. In the background, there are overhead electrical wires and a building with illuminated windows. The sky has a purplish hue.\n"
     ]
    }
   ],
   "source": [
    "response = litellm.completion(\n",
    "    model=\"openai/https://clarifai.com/openai/chat-completion/models/gpt-4o\",  # Replace with your model URL\n",
    "    api_key=os.getenv(\"CLARIFAI_PAT\"),\n",
    "    api_base=\"https://api.clarifai.com/v2/ext/openai/v1\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Describe what you see in this image.\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(f\"Response: {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Always ensure your Clarifai PAT is set in the environment variables\n",
    "- For multimodal models, provide both text and image inputs as required\n",
    "- Tool calling support may vary depending on the model capabilities\n",
    "- Streaming responses are token-by-token and may have different formatting across SDKs\n",
    "- Error handling and retry logic should be implemented in production environments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing-logs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
