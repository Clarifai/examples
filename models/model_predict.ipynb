{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td>\n",
    "   <a target=\"_blank\" href=\"https://www.clarifai.com/\" ><img src=\"https://upload.wikimedia.org/wikipedia/commons/b/bc/Clarifai_Logo_FC_Web.png\" width=256/></a>\n",
    "</td>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td>\n",
    "<a href=\"https://colab.research.google.com/github/Clarifai/examples/blob/main/models/model_predict.ipynb\" target=\"_blank\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Colab\"></a>\n",
    "</td>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook provides an introduction to using the Clarifai SDK to interact with prediction APIs for various AI models. \n",
    "\n",
    "To get predictions for an input, you need to supply an input and the model you'd like to get predictions from. \n",
    "Input can be formed from any of url or filepath or raw bytes\n",
    "\n",
    "Notebook is structured into sections based on the type of input the models accept\n",
    " - Text\n",
    " - Image\n",
    " - Video\n",
    " - Audio\n",
    "\n",
    "The final section delves into the potential of configuring additional parameters (such as threshold and concepts) to enhance the flexibility of prediction operations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install clarifai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CLARIFAI_PAT\"] = \"PAT\" # replace with your own PAT key here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Guide to get your [PAT](https://docs.clarifai.com/clarifai-basics/authentication/personal-access-tokens)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Colab\n",
    "To access data files from Clarifai examples repo, you can clone the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Clarifai/examples.git\n",
    "%cd /content/examples/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing of Models\n",
    "\n",
    "\n",
    "Here's an example on how to list all models in Clarifai community filtered by model_type, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clarifai.client.app import App\n",
    "\n",
    "all_llm_community_models = App().list_models(filter_by={\"query\": \"LLM\",\n",
    "                                                        \"model_type_id\": \"text-to-text\"}, only_in_app=False)\n",
    "\n",
    "for llm_model in all_llm_community_models:\n",
    "  print(\"Model ID \", llm_model.id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Model Details\n",
    "\n",
    "Below cell is how to know more on details of model(description, usecases..etc) and info on training or other inference parameters(eg: temperature, top_k, max_tokens..etc for LLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clarifai.client.user import User\n",
    "gpt_4_model = User(user_id=\"openai\").app(app_id=\"chat-completion\").model(model_id=\"GPT-4\")\n",
    "print(gpt_4_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model class objects can be inititalised by providing its URL or also by defining respective `user_id`, `app_id` and `model_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Model class\n",
    "from clarifai.client.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\"https://clarifai.com/clarifai/main/models/general-image-recognition\")\n",
    "                    # or\n",
    "model = Model(user_id=\"clarifai\", app_id=\"main\", model_id=\"general-image-recognition\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-to-Text\n",
    "\n",
    "Model takes text data as input by filename or bytes or url.\n",
    "\n",
    "Below is an example of how you would send text bytes/filepath and receive predictions from Clarifai's hosted models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict by Bytes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Generation** - Generating text from an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asking Claude2 to write a tweet on future of AI\n",
    "model_url = \"https://clarifai.com/anthropic/completion/models/claude-v2\"\n",
    "model_prediction = Model(model_url).predict_by_bytes(b\"Write a tweet on future of AI\", input_type=\"text\")\n",
    "\n",
    "# Get the output\n",
    "print(model_prediction.outputs[-1].data.text.raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict by FilePath"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Classification** - Sentiment Classification for given text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text sentiment analysis with 3 classes positive, negative, neutral.\n",
    "model_url = \"https://clarifai.com/erfan/text-classification/models/sentiment-analysis-twitter-roberta-base\"\n",
    "file_path = \"datasets/upload/data/text_files/positive/0_9.txt\"\n",
    "model_prediction = Model(model_url).predict_by_filepath(file_path, input_type=\"text\")\n",
    "\n",
    "# Get the output\n",
    "print(model_prediction.outputs[-1].data.concepts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-To-Image\n",
    "\n",
    "**Image Generation** - Generate an Image from given input Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Generation using Stable Diffusion XL\n",
    "model_url = \"https://clarifai.com/stability-ai/stable-diffusion-2/models/stable-diffusion-xl\"\n",
    "model_prediction = Model(model_url).predict_by_bytes(b\"A painting of a cat\", input_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base64 image to numpy array\n",
    "im_b = model_prediction.outputs[0].data.image.base64\n",
    "image_np = np.frombuffer(im_b, np.uint8)\n",
    "img_np = cv2.imdecode(image_np, cv2.IMREAD_COLOR)  \n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(img_np[...,::-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-To-Audio\n",
    "Generate Audio from given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://clarifai.com/eleven-labs/audio-generation/models/speech-synthesis\"\n",
    "\n",
    "model_prediction = Model(model_url).predict_by_bytes(b\"Hello, How are you doing today!\", \"text\")\n",
    "\n",
    "# Save the audio file\n",
    "with open('output_audio.wav', mode='bx') as f:\n",
    "    f.write(model_prediction.outputs[0].data.audio.base64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-To-Text\n",
    "\n",
    "**Image Captioning** - Generate Caption for the given input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://clarifai.com/salesforce/blip/models/general-english-image-caption-blip\"\n",
    "image_url = \"https://s3.amazonaws.com/samples.clarifai.com/featured-models/image-captioning-statue-of-liberty.jpeg\"\n",
    "model_prediction = Model(model_url).predict_by_url(image_url, input_type=\"image\")\n",
    "\n",
    "# Get the output\n",
    "print(model_prediction.outputs[0].data.text.raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Image classification** - Below is an example of how you would send image URL and receive predictions from Clarifai's general-image-recognition model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = \"https://clarifai.com/clarifai/main/models/general-image-recognition\"\n",
    "image_url = \"https://samples.clarifai.com/metro-north.jpg\"\n",
    "model_prediction = Model(model_url).predict_by_url(image_url, input_type=\"image\")\n",
    "\n",
    "# Get the output\n",
    "print(model_prediction.outputs[0].data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of inference on video input where we also define `sample_ms` parameter to run prediction every 2000ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEER_VIDEO_URL = \"https://samples.clarifai.com/beer.mp4\"\n",
    "\n",
    "model = Model(\"https://clarifai.com/clarifai/main/models/general-image-recognition\",\n",
    "      output_config={\n",
    "          \"sample_ms\": 2000 #Run inference every 2 seconds\n",
    "      })\n",
    "\n",
    "model_prediction = model.predict_by_url(BEER_VIDEO_URL, input_type=\"video\")\n",
    "\n",
    "# Print the frame info and the first concept name in each frame\n",
    "for frame in model_prediction.outputs[0].data.frames:\n",
    "    print(f\"Frame Info: {frame.frame_info} Concept: {frame.data.concepts[0].name}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio to Text\n",
    "\n",
    "Transcribe Audio to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_url = \"https://s3.amazonaws.com/samples.clarifai.com/GoodMorning.wav\"\n",
    "model_url = \"https://clarifai.com/facebook/asr/models/asr-wav2vec2-large-robust-ft-swbd-300h-english\"\n",
    "model_prediction = Model(model_url).predict_by_url(audio_url, \"audio\")\n",
    "\n",
    "# Print the output\n",
    "print(model_prediction.outputs[0].data.text.raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Parameters\n",
    "You can set additional parameters to gain flexibility in the predict operation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Concepts\n",
    "By putting this additional parameter on your predict calls, you can receive predict value(s) for only the concepts that you want to. \n",
    "\n",
    "You can specify particular concepts by either their id and/or their name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clarifai_grpc.grpc.api import resources_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOG_IMAGE_URL = \"https://samples.clarifai.com/dog2.jpeg\"\n",
    "Model_URL = \"https://clarifai.com/clarifai/main/models/general-image-recognition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_concepts = [\n",
    "      resources_pb2.Concept(name=\"dog\"),\n",
    "      resources_pb2.Concept(name=\"cat\"),\n",
    "  ]\n",
    "model = Model(Model_URL,\n",
    "    output_config={\n",
    "        \"select_concepts\": selected_concepts\n",
    "    })\n",
    "\n",
    "model_prediction = model.predict_by_url(DOG_IMAGE_URL, input_type=\"image\")\n",
    "\n",
    "# Print the output\n",
    "print(model_prediction.outputs[0].data.concepts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Concepts\n",
    "\n",
    "Setting the `max_concepts` parameter will customize how many concepts and their corresponding probability scores the predict endpoint will return. \n",
    "\n",
    "If not specified, the predict endpoint will return the top 20 concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(Model_URL,\n",
    "      output_config={\n",
    "          \"max_concepts\": 3\n",
    "      })\n",
    "\n",
    "model_prediction = model.predict_by_url(DOG_IMAGE_URL, input_type=\"image\")\n",
    "\n",
    "# Print the output\n",
    "print(model_prediction.outputs[0].data.concepts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Prediction Value\n",
    "\n",
    "This parameter lets you set a minimum probability threshold for the outputs you want to view for the Predict operation.\n",
    "\n",
    "For example if you want to see all concepts with a probability score of .95 or higher, this parameter will allow you to accomplish that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(Model_URL,\n",
    "        output_config={\n",
    "            \"min_value\": 0.95\n",
    "        })\n",
    "model_prediction = model.predict_by_url(DOG_IMAGE_URL, input_type=\"image\")\n",
    "\n",
    "# Print the output\n",
    "print(model_prediction.outputs[0].data.concepts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Model Version ID\n",
    "By specifying model_version_id in your predict call, you can continue to predict on a previous version, for consistent prediction results. Clarifai also updates its pre-built models on a regular basis.\n",
    "\n",
    "Below is an example of how you would set a model version ID and receive predictions from Clarifai's `general-image-recognition` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version_id = \"aa7f35c01e0642fda5cf400f543e7c40\"\n",
    "model_url = f\"https://clarifai.com/clarifai/main/models/general-image-recognition/model_version/{model_version_id}\"\n",
    "\n",
    "model = Model(model_url)\n",
    "\n",
    "model_prediction = model.predict_by_url(DOG_IMAGE_URL, input_type=\"image\")\n",
    "\n",
    "# Print the output\n",
    "print(model_prediction.outputs[0].data.concepts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarifai Resources\n",
    "\n",
    "**Website**: [https://www.clarifai.com](https://www.clarifai.com/)\n",
    "\n",
    "**Demo**: [https://clarifai.com/demo](https://clarifai.com/demo)\n",
    "\n",
    "**Sign up for a free Account**: [https://clarifai.com/signup](https://clarifai.com/signup)\n",
    "\n",
    "**Developer Guide**: [https://docs.clarifai.com](https://docs.clarifai.com/)\n",
    "\n",
    "**Clarifai Community**: [https://clarifai.com/explore](https://clarifai.com/explore)\n",
    "\n",
    "**Python SDK Docs**: [https://clarifai-python.readthedocs.io/en/latest/index.html](https://clarifai-python.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cl-py-utils",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
