torch==2.5.1
tokenizers>=0.21.0
transformers>=4.47.0
accelerate>=1.2.0
scipy==1.10.1
optimum>=1.23.3
xformers==0.0.28.post3
protobuf==5.27.3
einops>=0.8.0
requests==2.32.2

sglang[all]==0.3.6
orjson==3.10.11
python-multipart==0.0.17

--extra-index-url https://flashinfer.ai/whl/cu124/torch2.4/
flashinfer
bitsandbytes==0.45.0
