torch==2.4
tokenizers
transformers==4.46.2
accelerate
optimum
xformers
einops
requests==2.32.2
packaging
ninja
protobuf==3.20.0

sglang[all]
orjson
python-multipart

--extra-index-url https://flashinfer.ai/whl/cu121/torch2.4/
flashinfer
