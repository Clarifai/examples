torch==2.5.1
tokenizers==0.21.0
transformers>=4.47
accelerate==1.2.0
optimum==1.23.3
xformers
einops==0.8.0
requests==2.32.2
packaging
ninja
protobuf==3.20.0

sglang[all]==0.4.1.post7
orjson==3.10.11
python-multipart==0.0.17

--extra-index-url https://flashinfer.ai/whl/cu124/torch2.4/
flashinfer
